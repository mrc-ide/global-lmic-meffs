[ name       ]  brt_google_mobility
[ id         ]  20200708-072104-953f1422
[ resource   ]  World_Bank_Country_Metadata.csv
[ ...        ]  acaps.xlsx
[ parameter  ]  date: 2020-05-09
[ ...        ]  short_run: FALSE
[ start      ]  2020-07-08 07:21:04
[ parameter  ]  date: 2020-05-09
[ ...        ]  short_run: FALSE

Attaching package: ‘lubridate’

The following objects are masked from ‘package:base’:

    date, intersect, setdiff, union


Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loaded gbm 2.1.5
Loading required package: raster
Loading required package: sp

Attaching package: ‘raster’

The following object is masked from ‘package:dplyr’:

    select


Attaching package: ‘tidyr’

The following object is masked from ‘package:raster’:

    extract


> library(gbm)

> library(dismo)

> library(conflicted)

> library(gtools)

> library(lubridate)

> conflict_prefer("select", "dplyr")
[conflicted] Will prefer dplyr::select over any other package

> conflict_prefer("filter", "dplyr")
[conflicted] Will prefer dplyr::filter over any other package

> conflict_prefer("area", "patchwork")
[conflicted] Will prefer patchwork::area over any other package

> download_url <- function(url) {
+     tryCatch({
+         tf <- tempfile()
+         code <- download.file(url, tf, mode = "wb")
+         if (code != 0) {
+             stop("Error downloading file")
+         }
+     }, error = function(e) {
+         stop(sprintf("Error downloading file '%s': %s, please check %s", 
+             url, e$message))
+     })
+     return(tf)
+ }

> match_clean <- function(a, b, quiet = TRUE) {
+     a <- gsub("[[:punct:][:space:]]", "", tolower(stringi::stri_trans_general(a, 
+         "latin-ascii")))
+     b <- gsub("[[:punct:][:space:]]", "", tolower(stringi::stri_trans_general(b, 
+         "latin-ascii")))
+     ret <- match(a, b)
+     if (sum(is.na(ret) > 0)) {
+         dists <- stringdist::seq_distmatrix(lapply(a, utf8ToInt), 
+             lapply(b, utf8ToInt))
+         ret[is.na(ret)] <- apply(dists[which(is.na(ret)), , drop = FALSE], 
+             1, which.min)
+         if (!quiet) {
+             return(unique(cbind(a, b[ret])))
+         }
+     }
+     return(ret)
+ }

> date <- as.Date(date)

> goog_tf <- download_url("https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv")

> goog <- read.csv(goog_tf, stringsAsFactors = FALSE)

> goog$iso3c <- countrycode::countrycode(goog$country_region, 
+     "country.name", "iso3c")

> mob <- goog %>% filter(sub_region_1 == "") %>% mutate(overall = 1/4 * 
+     retail_and_recreation_percent_change_from_baseline + 1/4 * 
+     grocery_and_pharmacy_percent_change_from_baseline + 1/4 * 
+     transit_stations_percent_change_from_baseline + 1/4 * workplaces_percent_change_from_baseline) %>% 
+     mutate(date = as.Date(date, format = "%Y-%m-%d")) %>% select(country_region, 
+     iso3c, date, overall)

> wb_metadata <- read.csv("World_Bank_Country_Metadata.csv", 
+     fileEncoding = "UTF-8-BOM") %>% rename(ISO = country_code) %>% 
+     select(ISO, income_group, region) %>% filter(region != "")

> acap_site <- "http://www.acaps.org/covid19-government-measures-dataset"

> xml <- xml2::read_html(acap_site)

> url <- rvest::html_attr(rvest::html_nodes(xml, ".file a"), 
+     "href")

> acap_tf <- download_url(url)

> acap <- readxl::read_excel(acap_tf, progress = FALSE, 
+     sheet = "Database")

> acap$ISO <- countrycode::countrycode(acap$COUNTRY, 
+     "country.name", "iso3c", custom_match = c(Eswatini = "SWZ", 
+         Micronesia = "FSM"))

> ACAPs_measure <- acap %>% rename(country = COUNTRY, 
+     measure = MEASURE, type = LOG_TYPE, date = DATE_IMPLEMENTED) %>% 
+     select(ISO, measure, type, date) %>% filter(measure != "", 
+     type != "") %>% mutate(measure = as.numeric(factor(measure)), 
+     type = as.numeric(factor(type))) %>% mutate(combined = as.factor(paste0("m_", 
+     type, "_", measure))) %>% mutate(date = as.Date(date)) %>% 
+     select(ISO, date, combined) %>% pivot_wider(names_from = combined, 
+     values_from = combined) %>% filter(!is.na(date))

> measures <- colnames(ACAPs_measure)[-(1:2)]

> for (i in 1:length(measures)) {
+     index <- measures[i]
+     ACAPs_measure[, index] <- unlist(lapply(ACAPs_measure[[index]], 
+         length))
+ }

> new_ACAPs_measure <- ACAPs_measure %>% group_by(ISO) %>% 
+     arrange(date) %>% mutate_at(vars(-ISO, -date), funs(cumsum(.))) %>% 
+     complete(date = seq.Date(min(ACAPs_measure$date), max(ACAPs_measure$date), 
+         by = "days")) %>% mutate_at(vars(-ISO, -date), funs(replace(., 
+     row_number() == 1, 0)))

> column_names <- colnames(new_ACAPs_measure)[-c(1:2)]

> new_ACAPs_cat <- fill(new_ACAPs_measure, column_names, 
+     .direction = c("down"))
Note: Using an external vector in selections is ambiguous.
ℹ Use `all_of(column_names)` instead of `column_names` to silence this message.
ℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.
This message is displayed once per session.

> overall <- new_ACAPs_cat %>% left_join(mob, by = c(ISO = "iso3c", 
+     date = "date")) %>% filter(!is.na(overall)) %>% left_join(wb_metadata, 
+     by = "ISO") %>% select(-country_region)

> overall_test <- overall %>% ungroup(ISO) %>% select(overall, 
+     everything(), -ISO, -date)

> tree_complexity <- 8

> bag_fraction <- 0.5

> if (short_run) {
+     max_trees <- 30
+ } else {
+     max_trees <- 3000
+ }

> learning_rate <- 0.05

> x <- as.data.frame(overall_test)

> brt <- gbm.step(data = x, gbm.x = 2:ncol(x), gbm.y = 1, 
+     family = "gaussian", tree.complexity = tree_complexity, learning.rate = learning_rate, 
+     bag.fraction = bag_fraction, max.trees = max_trees, n.folds = 5, 
+     plot.main = FALSE, plot.folds = FALSE)

 
 GBM STEP - version 2.9 
 
Performing cross-validation optimisation of a boosted regression tree model 
for overall and using a family of gaussian 
Using 17952 observations and 81 predictors 
creating 5 initial models of 50 trees 

 folds are unstratified 
total mean deviance =  567.6308 
tolerance is fixed at  0.5676 
ntrees resid. dev. 
50    182.902 
now adding trees... 
100   131.7703 
150   111.9341 
200   101.072 
250   93.5987 
300   88.5273 
350   84.5084 
400   81.1591 
450   78.5388 
500   76.4246 
550   74.6029 
600   73.1164 
650   71.8087 
700   70.6404 
750   69.6664 
800   68.9115 
850   68.2155 
900   67.522 
950   67.0191 
1000   66.4976 
1050   65.9484 
1100   65.4752 
1150   65.0644 
1200   64.6509 
1250   64.274 
1300   63.9984 
1350   63.7059 
1400   63.4837 
1450   63.22 
1500   62.9965 
1550   62.8301 
1600   62.6034 
1650   62.4003 
1700   62.2486 
1750   62.0454 
1800   61.9071 
1850   61.7905 
1900   61.626 
1950   61.4972 
2000   61.3919 
2050   61.255 
2100   61.1049 
2150   61.0374 
2200   60.9501 
2250   60.8212 
2300   60.7042 
2350   60.6118 
2400   60.4918 
2450   60.3262 
2500   60.2656 
2550   60.1892 
2600   60.033 
2650   60.019 
2700   59.9377 
2750   59.8879 
2800   59.8305 
2850   59.7792 
2900   59.7163 
2950   59.6761 
3000   59.5798 
fitting final gbm model with a fixed number of 3000 trees for overall

mean total deviance = 567.631 
mean residual deviance = 49.331 
 
estimated cv deviance = 59.58 ; se = 0.519 
 
training data correlation = 0.956 
cv correlation =  0.946 ; se = 0.001 
 
elapsed time -  0.46 minutes 

 ########### warning ########## 
 
maximum tree limit reached - results may not be optimal 
  - refit with faster learning rate or increase maximum number of trees 

> output_data <- new_ACAPs_cat %>% left_join(mob, by = c(ISO = "iso3c", 
+     date = "date")) %>% left_join(wb_metadata, by = "ISO") %>% 
+     ungroup(ISO) %>% select(overall, everything(), -country_region)

> predicted <- predict.gbm(brt, output_data[which(is.na(output_data$overall)), 
+     c(4:(ncol(output_data)))], n.trees = brt$gbm.call$best.trees, 
+     type = "response")

> output_data$observed <- !is.na(output_data$overall)

> output_data$overall[which(is.na(output_data$overall))] <- predicted

> output_data$all_overall <- predict.gbm(brt, output_data[, 
+     c(4:(ncol(output_data)))], n.trees = brt$gbm.call$best.trees, 
+     type = "response")

> res <- select(output_data, ISO, date, overall, all_overall, 
+     observed, income_group) %>% mutate(overall = (overall + 100)/100, 
+     all_overall = (all_overall + 100)/100) %>% rename(C = overall, 
+     C_predict = all_overall, iso3c = ISO)

> res <- split.data.frame(res, res$iso3c)

> nms <- unique(squire::population$iso3c)

> res_no <- lapply(nms[!nms %in% names(res)], function(x) {
+     return(data.frame())
+ })

> names(res_no) <- nms[!nms %in% names(res)]

> res <- append(res, res_no)

> res <- lapply(res, function(x) {
+     if (nrow(x) > 0) {
+         return(as.data.frame(x))
+     }
+     else {
+         return(x)
+     }
+ })

> res <- lapply(res, function(x) {
+     if (length(unique(x$C)) == 1) {
+         x <- rbind(x[1, ], x)
+         x$date[1] <- x$date[2] - 1
+         x[1, "C"] <- 1
+     }
+     return(x)
+ })

> for (r in seq_along(res)) {
+     if (any(res[[r]]$observed)) {
+         lw <- res[[r]]$C[which(res[[r]]$observed)][1:7]
+         res[[r]]$C[1:(which(res[[r]]$observed)[1] - 1)] <- mean(lw)
+         rw <- tail(res[[r]]$C[which(res[[r]]$observed)], 14)
+         rw_end <- tail(which(res[[r]]$observed), 1)
+         rw_7 <- res[[r]]$C[(rw_end + 1):(rw_end + 7)]
+         res[[r]]$C[(rw_end + 1):nrow(res[[r]])] <- mean(rw)
+     }
+ }

> saveRDS(res, "google_brt.rds")

> saveRDS(brt, "google_brt_model.rds")

> saveRDS(overall, "overall.rds")
[ end        ]  2020-07-08 07:49:24
[ elapsed    ]  Ran report in 28.33701 mins
[ artefact   ]  google_brt.rds: c8219d43a64abf3881f6ec2df876ba2e
[ ...        ]  google_brt_model.rds: 6011564212bf6537e374e562d735b06e
[ ...        ]  overall.rds: f13b3bf979d06a2ec7af11d4f99b08ed
[ commit     ]  brt_google_mobility/20200708-072104-953f1422
[ copy       ]

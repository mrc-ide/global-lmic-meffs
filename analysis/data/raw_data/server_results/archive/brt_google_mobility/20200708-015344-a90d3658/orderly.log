[ name       ]  brt_google_mobility
[ id         ]  20200708-015344-a90d3658
[ resource   ]  World_Bank_Country_Metadata.csv
[ ...        ]  acaps.xlsx
[ parameter  ]  date: 2020-05-30
[ ...        ]  short_run: FALSE
[ start      ]  2020-07-08 01:53:44
[ parameter  ]  date: 2020-05-30
[ ...        ]  short_run: FALSE

Attaching package: ‘lubridate’

The following objects are masked from ‘package:base’:

    date, intersect, setdiff, union


Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loaded gbm 2.1.5
Loading required package: raster
Loading required package: sp

Attaching package: ‘raster’

The following object is masked from ‘package:dplyr’:

    select


Attaching package: ‘tidyr’

The following object is masked from ‘package:raster’:

    extract


> library(gbm)

> library(dismo)

> library(conflicted)

> library(gtools)

> library(lubridate)

> conflict_prefer("select", "dplyr")
[conflicted] Will prefer dplyr::select over any other package

> conflict_prefer("filter", "dplyr")
[conflicted] Will prefer dplyr::filter over any other package

> conflict_prefer("area", "patchwork")
[conflicted] Will prefer patchwork::area over any other package

> download_url <- function(url) {
+     tryCatch({
+         tf <- tempfile()
+         code <- download.file(url, tf, mode = "wb")
+         if (code != 0) {
+             stop("Error downloading file")
+         }
+     }, error = function(e) {
+         stop(sprintf("Error downloading file '%s': %s, please check %s", 
+             url, e$message))
+     })
+     return(tf)
+ }

> match_clean <- function(a, b, quiet = TRUE) {
+     a <- gsub("[[:punct:][:space:]]", "", tolower(stringi::stri_trans_general(a, 
+         "latin-ascii")))
+     b <- gsub("[[:punct:][:space:]]", "", tolower(stringi::stri_trans_general(b, 
+         "latin-ascii")))
+     ret <- match(a, b)
+     if (sum(is.na(ret) > 0)) {
+         dists <- stringdist::seq_distmatrix(lapply(a, utf8ToInt), 
+             lapply(b, utf8ToInt))
+         ret[is.na(ret)] <- apply(dists[which(is.na(ret)), , drop = FALSE], 
+             1, which.min)
+         if (!quiet) {
+             return(unique(cbind(a, b[ret])))
+         }
+     }
+     return(ret)
+ }

> date <- as.Date(date)

> goog_tf <- download_url("https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv")

> goog <- read.csv(goog_tf, stringsAsFactors = FALSE)

> goog$iso3c <- countrycode::countrycode(goog$country_region, 
+     "country.name", "iso3c")

> mob <- goog %>% filter(sub_region_1 == "") %>% mutate(overall = 1/4 * 
+     retail_and_recreation_percent_change_from_baseline + 1/4 * 
+     grocery_and_pharmacy_percent_change_from_baseline + 1/4 * 
+     transit_stations_percent_change_from_baseline + 1/4 * workplaces_percent_change_from_baseline) %>% 
+     mutate(date = as.Date(date, format = "%Y-%m-%d")) %>% select(country_region, 
+     iso3c, date, overall)

> wb_metadata <- read.csv("World_Bank_Country_Metadata.csv", 
+     fileEncoding = "UTF-8-BOM") %>% rename(ISO = country_code) %>% 
+     select(ISO, income_group, region) %>% filter(region != "")

> acap_site <- "http://www.acaps.org/covid19-government-measures-dataset"

> xml <- xml2::read_html(acap_site)

> url <- rvest::html_attr(rvest::html_nodes(xml, ".file a"), 
+     "href")

> acap_tf <- download_url(url)

> acap <- readxl::read_excel(acap_tf, progress = FALSE, 
+     sheet = "Database")

> acap$ISO <- countrycode::countrycode(acap$COUNTRY, 
+     "country.name", "iso3c", custom_match = c(Eswatini = "SWZ", 
+         Micronesia = "FSM"))

> ACAPs_measure <- acap %>% rename(country = COUNTRY, 
+     measure = MEASURE, type = LOG_TYPE, date = DATE_IMPLEMENTED) %>% 
+     select(ISO, measure, type, date) %>% filter(measure != "", 
+     type != "") %>% mutate(measure = as.numeric(factor(measure)), 
+     type = as.numeric(factor(type))) %>% mutate(combined = as.factor(paste0("m_", 
+     type, "_", measure))) %>% mutate(date = as.Date(date)) %>% 
+     select(ISO, date, combined) %>% pivot_wider(names_from = combined, 
+     values_from = combined) %>% filter(!is.na(date))

> measures <- colnames(ACAPs_measure)[-(1:2)]

> for (i in 1:length(measures)) {
+     index <- measures[i]
+     ACAPs_measure[, index] <- unlist(lapply(ACAPs_measure[[index]], 
+         length))
+ }

> new_ACAPs_measure <- ACAPs_measure %>% group_by(ISO) %>% 
+     arrange(date) %>% mutate_at(vars(-ISO, -date), funs(cumsum(.))) %>% 
+     complete(date = seq.Date(min(ACAPs_measure$date), max(ACAPs_measure$date), 
+         by = "days")) %>% mutate_at(vars(-ISO, -date), funs(replace(., 
+     row_number() == 1, 0)))

> column_names <- colnames(new_ACAPs_measure)[-c(1:2)]

> new_ACAPs_cat <- fill(new_ACAPs_measure, column_names, 
+     .direction = c("down"))
Note: Using an external vector in selections is ambiguous.
ℹ Use `all_of(column_names)` instead of `column_names` to silence this message.
ℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.
This message is displayed once per session.

> overall <- new_ACAPs_cat %>% left_join(mob, by = c(ISO = "iso3c", 
+     date = "date")) %>% filter(!is.na(overall)) %>% left_join(wb_metadata, 
+     by = "ISO") %>% select(-country_region)

> overall_test <- overall %>% ungroup(ISO) %>% select(overall, 
+     everything(), -ISO, -date)

> tree_complexity <- 8

> bag_fraction <- 0.5

> if (short_run) {
+     max_trees <- 30
+ } else {
+     max_trees <- 3000
+ }

> learning_rate <- 0.05

> x <- as.data.frame(overall_test)

> brt <- gbm.step(data = x, gbm.x = 2:ncol(x), gbm.y = 1, 
+     family = "gaussian", tree.complexity = tree_complexity, learning.rate = learning_rate, 
+     bag.fraction = bag_fraction, max.trees = max_trees, n.folds = 5, 
+     plot.main = FALSE, plot.folds = FALSE)

 
 GBM STEP - version 2.9 
 
Performing cross-validation optimisation of a boosted regression tree model 
for overall and using a family of gaussian 
Using 17952 observations and 81 predictors 
creating 5 initial models of 50 trees 

 folds are unstratified 
total mean deviance =  567.6308 
tolerance is fixed at  0.5676 
ntrees resid. dev. 
50    183.4053 
now adding trees... 
100   132.2814 
150   112.3927 
200   101.7954 
250   94.7263 
300   89.5082 
350   85.2856 
400   81.9699 
450   79.2017 
500   77.1719 
550   75.3057 
600   73.7117 
650   72.422 
700   71.287 
750   70.2746 
800   69.3958 
850   68.6176 
900   68.028 
950   67.4086 
1000   67.027 
1050   66.5583 
1100   66.093 
1150   65.6529 
1200   65.3347 
1250   65.0235 
1300   64.8051 
1350   64.4767 
1400   64.2394 
1450   63.9785 
1500   63.8309 
1550   63.6208 
1600   63.4403 
1650   63.316 
1700   63.1286 
1750   62.8972 
1800   62.7382 
1850   62.6052 
1900   62.5116 
1950   62.3536 
2000   62.2015 
2050   62.052 
2100   61.9965 
2150   61.934 
2200   61.811 
2250   61.6669 
2300   61.6415 
2350   61.5072 
2400   61.4534 
2450   61.3926 
2500   61.2948 
2550   61.2403 
2600   61.1337 
2650   61.063 
2700   60.9794 
2750   60.9022 
2800   60.7873 
2850   60.7338 
2900   60.7061 
2950   60.6529 
3000   60.627 
fitting final gbm model with a fixed number of 3000 trees for overall

mean total deviance = 567.631 
mean residual deviance = 49.498 
 
estimated cv deviance = 60.627 ; se = 1.012 
 
training data correlation = 0.955 
cv correlation =  0.945 ; se = 0.001 
 
elapsed time -  0.46 minutes 

 ########### warning ########## 
 
maximum tree limit reached - results may not be optimal 
  - refit with faster learning rate or increase maximum number of trees 

> output_data <- new_ACAPs_cat %>% left_join(mob, by = c(ISO = "iso3c", 
+     date = "date")) %>% left_join(wb_metadata, by = "ISO") %>% 
+     ungroup(ISO) %>% select(overall, everything(), -country_region)

> predicted <- predict.gbm(brt, output_data[which(is.na(output_data$overall)), 
+     c(4:(ncol(output_data)))], n.trees = brt$gbm.call$best.trees, 
+     type = "response")

> output_data$observed <- !is.na(output_data$overall)

> output_data$overall[which(is.na(output_data$overall))] <- predicted

> output_data$all_overall <- predict.gbm(brt, output_data[, 
+     c(4:(ncol(output_data)))], n.trees = brt$gbm.call$best.trees, 
+     type = "response")

> res <- select(output_data, ISO, date, overall, all_overall, 
+     observed, income_group) %>% mutate(overall = (overall + 100)/100, 
+     all_overall = (all_overall + 100)/100) %>% rename(C = overall, 
+     C_predict = all_overall, iso3c = ISO)

> res <- split.data.frame(res, res$iso3c)

> nms <- unique(squire::population$iso3c)

> res_no <- lapply(nms[!nms %in% names(res)], function(x) {
+     return(data.frame())
+ })

> names(res_no) <- nms[!nms %in% names(res)]

> res <- append(res, res_no)

> res <- lapply(res, function(x) {
+     if (nrow(x) > 0) {
+         return(as.data.frame(x))
+     }
+     else {
+         return(x)
+     }
+ })

> res <- lapply(res, function(x) {
+     if (length(unique(x$C)) == 1) {
+         x <- rbind(x[1, ], x)
+         x$date[1] <- x$date[2] - 1
+         x[1, "C"] <- 1
+     }
+     return(x)
+ })

> for (r in seq_along(res)) {
+     if (any(res[[r]]$observed)) {
+         lw <- res[[r]]$C[which(res[[r]]$observed)][1:7]
+         res[[r]]$C[1:(which(res[[r]]$observed)[1] - 1)] <- mean(lw)
+         rw <- tail(res[[r]]$C[which(res[[r]]$observed)], 14)
+         rw_end <- tail(which(res[[r]]$observed), 1)
+         rw_7 <- res[[r]]$C[(rw_end + 1):(rw_end + 7)]
+         res[[r]]$C[(rw_end + 1):nrow(res[[r]])] <- mean(rw)
+     }
+ }

> saveRDS(res, "google_brt.rds")

> saveRDS(brt, "google_brt_model.rds")

> saveRDS(overall, "overall.rds")
[ end        ]  2020-07-08 02:21:55
[ elapsed    ]  Ran report in 28.18461 mins
[ artefact   ]  google_brt.rds: 2f3850549d5e857f2e6f2fec3a168b88
[ ...        ]  google_brt_model.rds: a7002165c4e1b0986034409762215313
[ ...        ]  overall.rds: f13b3bf979d06a2ec7af11d4f99b08ed
[ commit     ]  brt_google_mobility/20200708-015344-a90d3658
[ copy       ]

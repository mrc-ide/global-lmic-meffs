[ name       ]  brt_google_mobility
[ id         ]  20200617-160036-65113018
[ resource   ]  World_Bank_Country_Metadata.csv
[ ...        ]  acaps.xlsx
[ parameter  ]  date: 2020-06-17
[ ...        ]  short_run: FALSE
[ start      ]  2020-06-17 16:00:36
[ parameter  ]  date: 2020-06-17
[ ...        ]  short_run: FALSE

Attaching package: ‘lubridate’

The following objects are masked from ‘package:base’:

    date, intersect, setdiff, union


Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loaded gbm 2.1.5
Loading required package: raster
Loading required package: sp

Attaching package: ‘raster’

The following object is masked from ‘package:dplyr’:

    select


Attaching package: ‘tidyr’

The following object is masked from ‘package:raster’:

    extract


> library(gbm)

> library(dismo)

> library(conflicted)

> library(gtools)

> library(lubridate)

> conflict_prefer("select", "dplyr")
[conflicted] Will prefer dplyr::select over any other package

> conflict_prefer("filter", "dplyr")
[conflicted] Will prefer dplyr::filter over any other package

> conflict_prefer("area", "patchwork")
[conflicted] Will prefer patchwork::area over any other package

> download_url <- function(url) {
+     tryCatch({
+         tf <- tempfile()
+         code <- download.file(url, tf, mode = "wb")
+         if (code != 0) {
+             stop("Error downloading file")
+         }
+     }, error = function(e) {
+         stop(sprintf("Error downloading file '%s': %s, please check %s", 
+             url, e$message))
+     })
+     return(tf)
+ }

> match_clean <- function(a, b, quiet = TRUE) {
+     a <- gsub("[[:punct:][:space:]]", "", tolower(stringi::stri_trans_general(a, 
+         "latin-ascii")))
+     b <- gsub("[[:punct:][:space:]]", "", tolower(stringi::stri_trans_general(b, 
+         "latin-ascii")))
+     ret <- match(a, b)
+     if (sum(is.na(ret) > 0)) {
+         dists <- stringdist::seq_distmatrix(lapply(a, utf8ToInt), 
+             lapply(b, utf8ToInt))
+         ret[is.na(ret)] <- apply(dists[which(is.na(ret)), , drop = FALSE], 
+             1, which.min)
+         if (!quiet) {
+             return(unique(cbind(a, b[ret])))
+         }
+     }
+     return(ret)
+ }

> date <- as.Date(date)

> goog_tf <- download_url("https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv")

> goog <- read.csv(goog_tf, stringsAsFactors = FALSE)

> goog$iso3c <- countrycode::countrycode(goog$country_region, 
+     "country.name", "iso3c")

> mob <- goog %>% filter(sub_region_1 == "") %>% mutate(overall = 1/4 * 
+     retail_and_recreation_percent_change_from_baseline + 1/4 * 
+     grocery_and_pharmacy_percent_change_from_baseline + 1/4 * 
+     transit_stations_percent_change_from_baseline + 1/4 * workplaces_percent_change_from_baseline) %>% 
+     mutate(date = as.Date(date, format = "%Y-%m-%d")) %>% select(country_region, 
+     iso3c, date, overall)

> wb_metadata <- read.csv("World_Bank_Country_Metadata.csv", 
+     fileEncoding = "UTF-8-BOM") %>% rename(ISO = country_code) %>% 
+     select(ISO, income_group, region) %>% filter(region != "")

> acap_site <- "http://www.acaps.org/covid19-government-measures-dataset"

> xml <- xml2::read_html(acap_site)

> url <- rvest::html_attr(rvest::html_nodes(xml, ".file a"), 
+     "href")

> acap_tf <- download_url(url)

> acap <- readxl::read_excel(acap_tf, progress = FALSE, 
+     sheet = "Database")

> acap$ISO <- countrycode::countrycode(acap$COUNTRY, 
+     "country.name", "iso3c", custom_match = c(Eswatini = "SWZ", 
+         Micronesia = "FSM"))

> ACAPs_measure <- acap %>% rename(country = COUNTRY, 
+     measure = MEASURE, type = LOG_TYPE, date = DATE_IMPLEMENTED) %>% 
+     select(ISO, measure, type, date) %>% filter(measure != "", 
+     type != "") %>% mutate(measure = as.numeric(factor(measure)), 
+     type = as.numeric(factor(type))) %>% mutate(combined = as.factor(paste0("m_", 
+     type, "_", measure))) %>% mutate(date = as.Date(date)) %>% 
+     select(ISO, date, combined) %>% pivot_wider(names_from = combined, 
+     values_from = combined) %>% filter(!is.na(date))

> measures <- colnames(ACAPs_measure)[-(1:2)]

> for (i in 1:length(measures)) {
+     index <- measures[i]
+     ACAPs_measure[, index] <- unlist(lapply(ACAPs_measure[[index]], 
+         length))
+ }

> new_ACAPs_measure <- ACAPs_measure %>% group_by(ISO) %>% 
+     arrange(date) %>% mutate_at(vars(-ISO, -date), funs(cumsum(.))) %>% 
+     complete(date = seq.Date(min(ACAPs_measure$date), max(ACAPs_measure$date), 
+         by = "days")) %>% mutate_at(vars(-ISO, -date), funs(replace(., 
+     row_number() == 1, 0)))

> column_names <- colnames(new_ACAPs_measure)[-c(1:2)]

> new_ACAPs_cat <- fill(new_ACAPs_measure, column_names, 
+     .direction = c("down"))
Note: Using an external vector in selections is ambiguous.
ℹ Use `all_of(column_names)` instead of `column_names` to silence this message.
ℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.
This message is displayed once per session.

> overall <- new_ACAPs_cat %>% left_join(mob, by = c(ISO = "iso3c", 
+     date = "date")) %>% filter(!is.na(overall)) %>% left_join(wb_metadata, 
+     by = "ISO") %>% select(-country_region)

> overall_test <- overall %>% ungroup(ISO) %>% select(overall, 
+     everything(), -ISO, -date)

> tree_complexity <- 8

> bag_fraction <- 0.5

> if (short_run) {
+     max_trees <- 30
+ } else {
+     max_trees <- 3000
+ }

> learning_rate <- 0.05

> x <- as.data.frame(overall_test)

> brt <- gbm.step(data = x, gbm.x = 2:ncol(x), gbm.y = 1, 
+     family = "gaussian", tree.complexity = tree_complexity, learning.rate = learning_rate, 
+     bag.fraction = bag_fraction, max.trees = max_trees, n.folds = 5, 
+     plot.main = FALSE, plot.folds = FALSE)

 
 GBM STEP - version 2.9 
 
Performing cross-validation optimisation of a boosted regression tree model 
for overall and using a family of gaussian 
Using 15382 observations and 80 predictors 
creating 5 initial models of 50 trees 

 folds are unstratified 
total mean deviance =  611.8865 
tolerance is fixed at  0.6119 
ntrees resid. dev. 
50    179.8363 
now adding trees... 
100   132.1122 
150   113.5102 
200   103.3097 
250   96.4696 
300   91.5765 
350   87.7097 
400   84.611 
450   82.0972 
500   80.1712 
550   78.3405 
600   76.9005 
650   75.6585 
700   74.7221 
750   73.7581 
800   72.9861 
850   72.3413 
900   71.8411 
950   71.0762 
1000   70.5823 
1050   70.1914 
1100   69.6735 
1150   69.0867 
1200   68.8284 
1250   68.5239 
1300   68.3272 
1350   67.9929 
1400   67.7103 
1450   67.4727 
1500   67.2576 
1550   67.0217 
1600   66.8524 
1650   66.6469 
1700   66.4584 
1750   66.2681 
1800   66.1589 
1850   66.0048 
1900   65.932 
1950   65.739 
2000   65.6353 
2050   65.5347 
2100   65.3956 
2150   65.3235 
2200   65.0995 
2250   64.9772 
2300   64.8208 
2350   64.7507 
2400   64.6219 
2450   64.5394 
2500   64.5134 
2550   64.4092 
2600   64.3578 
2650   64.3282 
2700   64.214 
2750   64.1963 
2800   64.113 
2850   64.1065 
2900   64.101 
2950   64.0093 
3000   63.9761 
fitting final gbm model with a fixed number of 3000 trees for overall

mean total deviance = 611.887 
mean residual deviance = 51.933 
 
estimated cv deviance = 63.976 ; se = 0.854 
 
training data correlation = 0.957 
cv correlation =  0.946 ; se = 0.001 
 
elapsed time -  0.39 minutes 

 ########### warning ########## 
 
maximum tree limit reached - results may not be optimal 
  - refit with faster learning rate or increase maximum number of trees 

> output_data <- new_ACAPs_cat %>% left_join(mob, by = c(ISO = "iso3c", 
+     date = "date")) %>% left_join(wb_metadata, by = "ISO") %>% 
+     ungroup(ISO) %>% select(overall, everything(), -country_region)

> predicted <- predict.gbm(brt, output_data[which(is.na(output_data$overall)), 
+     c(4:(ncol(output_data)))], n.trees = brt$gbm.call$best.trees, 
+     type = "response")

> output_data$observed <- !is.na(output_data$overall)

> output_data$overall[which(is.na(output_data$overall))] <- predicted

> output_data$all_overall <- predict.gbm(brt, output_data[, 
+     c(4:(ncol(output_data)))], n.trees = brt$gbm.call$best.trees, 
+     type = "response")

> res <- select(output_data, ISO, date, overall, all_overall, 
+     observed, income_group) %>% mutate(overall = (overall + 100)/100, 
+     all_overall = (all_overall + 100)/100) %>% rename(C = overall, 
+     C_predict = all_overall, iso3c = ISO)

> res <- split.data.frame(res, res$iso3c)

> nms <- unique(squire::population$iso3c)

> res_no <- lapply(nms[!nms %in% names(res)], function(x) {
+     return(data.frame())
+ })

> names(res_no) <- nms[!nms %in% names(res)]

> res <- append(res, res_no)

> res <- lapply(res, function(x) {
+     if (nrow(x) > 0) {
+         return(as.data.frame(x))
+     }
+     else {
+         return(x)
+     }
+ })

> res <- lapply(res, function(x) {
+     if (length(unique(x$C)) == 1) {
+         x <- rbind(x[1, ], x)
+         x$date[1] <- x$date[2] - 1
+         x[1, "C"] <- 1
+     }
+     return(x)
+ })

> for (r in seq_along(res)) {
+     if (any(res[[r]]$observed)) {
+         lw <- res[[r]]$C[which(res[[r]]$observed)][1:7]
+         res[[r]]$C[1:(which(res[[r]]$observed)[1] - 1)] <- mean(lw)
+         rw <- tail(res[[r]]$C[which(res[[r]]$observed)], 14)
+         rw_end <- tail(which(res[[r]]$observed), 1)
+         rw_7 <- res[[r]]$C[(rw_end + 1):(rw_end + 7)]
+         res[[r]]$C[(rw_end + 1):nrow(res[[r]])] <- mean(rw)
+     }
+ }

> saveRDS(res, "google_brt.rds")

> saveRDS(brt, "google_brt_model.rds")

> saveRDS(overall, "overall.rds")
[ end        ]  2020-06-17 16:24:49
[ elapsed    ]  Ran report in 24.22453 mins
[ artefact   ]  google_brt.rds: 075b47a61b489df3901371f683d4a360
[ ...        ]  google_brt_model.rds: 069290cb0596f7e3e9ae66b94a2c4ef3
[ ...        ]  overall.rds: 0e85940a9828818e0d81ac1b40156e72
[ commit     ]  brt_google_mobility/20200617-160036-65113018
[ copy       ]
